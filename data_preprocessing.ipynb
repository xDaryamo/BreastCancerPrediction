{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xDaryamo/BreastCancerPrediction/blob/master/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tZDtS_XYRy-6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from tabulate import tabulate\n",
        "from string import punctuation\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1u9VXWGBp2M",
        "outputId": "a5ba73f6-c1d3-4ea9-ba7f-30eb059e5b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-27 15:20:05.171339: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[K     |████████████████████████████████| 460.3 MB 21 kB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 10.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 57.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 44.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 59.5 MB/s \n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n"
          ]
        }
      ],
      "source": [
        "#!python -m spacy download en_core_web_md\n",
        "!python -m spacy download en_core_web_trf --quiet\n",
        "!pip install spacy-transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "CSiEZ-Mg5rrJ"
      },
      "outputs": [],
      "source": [
        "import spacy_transformers\n",
        "nlp = spacy.load(\"en_core_web_trf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "WgjHQOuy5jdK"
      },
      "outputs": [],
      "source": [
        "def features(sentence):\n",
        "\n",
        "    \n",
        "    doc = nlp(sentence)\n",
        "    tokens = []\n",
        "    tokens_dep = []\n",
        "    tokens_pos = []\n",
        "\n",
        "    for token in doc:\n",
        "      if str(token) not in punctuation:\n",
        "        if token.ent_type_ == '':\n",
        "          tokens.append(token.text)\n",
        "        else:\n",
        "          tokens.append(token.ent_type_)\n",
        "\n",
        "    for token in doc:\n",
        "      if str(token) not in punctuation:\n",
        "        tokens_dep.append(token.dep_)\n",
        " \n",
        "    for token in doc:\n",
        "        if str(token) not in punctuation:\n",
        "            tokens_pos.append(token.pos_)\n",
        " \n",
        "    return tokens, tokens_dep, tokens_pos "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "bHce2jJ8Y_Nl"
      },
      "outputs": [],
      "source": [
        "def is_quote_ok(s):\n",
        "    stack = []\n",
        "    for c in s:\n",
        "        if c in [\"'\", '\"', \"`\"]:\n",
        "            if stack and stack[-1] == c:\n",
        "                stack.pop()\n",
        "            else:\n",
        "                stack.append(c)\n",
        "        else:\n",
        "            # ignore it\n",
        "            pass\n",
        "\n",
        "    return len(stack) == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SBFrDKPbZf3p"
      },
      "outputs": [],
      "source": [
        "def findWholeWord(keyword, string):\n",
        "  return re.search(r'\\b' + keyword + r'\\W', string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "HZtOOZfkqNIQ"
      },
      "outputs": [],
      "source": [
        "def is_member(sentence):\n",
        "  if re.search(\"^(\\(?[0-9]+\\s*)[\\)\\-](\\s+)?\", sentence):\n",
        "    sentence = re.sub(\"^(\\(?[0-9]+\\s*)[\\)\\-](\\s+)?\", '', sentence)\n",
        "    flag = True\n",
        "  elif re.search(\"^([\\-]+)(\\s+)?\", sentence):\n",
        "    sentence = re.sub(\"^([\\-]+)(\\s+)?\", '', sentence)\n",
        "    flag = True\n",
        "  elif re.search(\"^(\\(?[a-zA-Z]*)\\)+(\\s+)?\", sentence):\n",
        "    sentence = re.sub(\"^(\\(?[a-zA-Z]*)\\)+(\\s+)?\", '', sentence)\n",
        "    flag = True\n",
        "  elif re.search(\"^[a-z]\\.+[^g](\\s+)?\", sentence):\n",
        "    sentence = re.sub(\"^[a-z]\\.+[^g](\\s+)?\", '', sentence)\n",
        "    flag = True\n",
        "  elif re.search(\"^(• )+(\\s+)?\", sentence):\n",
        "    sentence = re.sub(\"^(• )+(\\s+)?\", '', sentence)\n",
        "    flag = True\n",
        "  else:\n",
        "    flag = False\n",
        "    \n",
        "  \n",
        "  return flag, sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "qafJv5gn1zXJ"
      },
      "outputs": [],
      "source": [
        "#Titoli paragrafi e sezioni\n",
        "def is_title(sentence):\n",
        "  return re.search(\"^((I|i)(N|n)|(D|d)(C|c))?\\.?([0-9])([\\.0-9]+)\", sentence) or re.search(\"^[A-Za-z]+\\s+((S|s)ection)\", sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "AqtEFDkb052t"
      },
      "outputs": [],
      "source": [
        "def is_skippable(sentence):\n",
        "\n",
        "  #ID delle User Stories\n",
        "  if re.search(\"^(User Story: )?US[0-9]+(\\.*[0-9])*\", sentence) or re.search(\"^(Technical Story: )?TS[0-9]+(\\.[0-9]*)*\", sentence):\n",
        "    return True\n",
        "    \n",
        "  #Solo caratteri speciali\n",
        "  elif re.search(\"^[\\W_]+$\", sentence) or re.search(\"^([\\|\\.\\;\\,\\@][\\d\\s\\w]?)+\", sentence) or re.search(\"^\\s*\\+\", sentence):\n",
        "    return True\n",
        "\n",
        "  #Tutte le frasi composte da solo 2 parole\n",
        "  elif len(re.findall('\\w+', sentence)) <= 2:\n",
        "    return True\n",
        "\n",
        "  #Le frasi 'None at present.' ricorrenti nel dataset\n",
        "  elif sentence == \"None at present.\":\n",
        "    return True\n",
        "\n",
        "  #Url\n",
        "  elif re.search(\"^https?:\\\\/\\\\/(?:www\\\\.)?[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)$\", sentence) or \\\n",
        "        (re.search(\"^([a-z\\-\\_]+\\.)+[a-z]+\", sentence) and not re.search(\"^(e\\.g\\.|E\\.g\\.)\\s*\", sentence)):\n",
        "    return True\n",
        "\n",
        "  #Didascalie tabelle e immagini\n",
        "  elif re.search(\"^(Figure|Table)\\s?[0-9]\", sentence):\n",
        "    return True\n",
        "\n",
        "  #Testi \"See also\"\n",
        "  elif re.search(\"^(See also|see also)\", sentence):\n",
        "    return True\n",
        "\n",
        "  #Email\n",
        "  elif re.search(\"^[a-zA-Z0-9.! #$%&'*+/=? ^_`{|}~-]+@[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)*$\", sentence):\n",
        "    return True\n",
        "\n",
        "  #Log message\n",
        "  elif re.search(\"^((L|l)og (m|M)essage|(f|F)eature (r|R)equest|(F|f)eature (I|i)(d|D))\", sentence):\n",
        "    return True\n",
        "\n",
        "  #Informazioni temporali\n",
        "  elif re.search(\"^(build date:)\", sentence) or \\\n",
        "        re.search(\"(?:\\\"|\\')?((J|j)an(?:uary)?|(F|f)eb(?:ruary)?|(M|m)ar(?:ch)?|(A|a)pr(?:il)?|(M|m)ay|(J|j)un(?:e)?|(J|j)ul(?:y)?|(A|a)ug(?:ust)?|(S|s)ept(?:ember)?|(S|s)ep(?:tember)?|(O|o)ct(?:ober)?|(N|n)ov(?:ember)?|(D|d)ec(?:ember)?)\\s+(\\d{1,2}(st|nd|rd|th)?)\\,?\\s+((\\d{4})\\s?)?((\\d{1,2}):\\d{1,2}\\s+(am|AM|Am|pm|Pm|PM)?)?\", sentence) or \\\n",
        "        re.search(\"\\d{4,4}-\\d{1,2}-\\d{1,2}\\s+((\\d{1,2}):\\d{1,2}\\s+(am|AM|Am|pm|Pm|PM)?)?\", sentence) or \\\n",
        "        re.search(\"^build date:\", sentence) or re.search(\"^(\\d(-| to | or )?\\s?)+((d|D)ays?|(m|M)onths? | (y|Y)ears? | (w|W)eeks?)\", sentence) or \\\n",
        "        re.search(\"^[\\d]+\\s(business )?(days?|weeks?|years?|months?)\", sentence):\n",
        "    return True\n",
        "  \n",
        "  #Frasi che indicano errori (iniziano con \"issue x\")\n",
        "  elif re.search(\"^(Issues?)\\s+\\d+\", sentence):\n",
        "    return True\n",
        "\n",
        "  elif re.search(\"^(org.|sun.|javax.|oscar.|net.|lang.|doinhibernate|qcvl.|qeh.|qgoatway.)\", sentence):\n",
        "    return True\n",
        "\n",
        "  elif re.search(\"^(Please note)[^:]*:$\", sentence) or re.search(\"(go to):?\\s*(https?:\\/\\/)?(\\w\\w\\w.)?[a-zA-z]+\", sentence):\n",
        "    return True\n",
        "\n",
        "  elif re.search(\"^(login|log in|logon|log on|logout|log out|(c|C)urrent functionality:|(r|R)equired new functionality:|WL:|(I|i)ntake \\d*)\", sentence):\n",
        "    return True\n",
        "\n",
        "  #Metodi o funzioni\n",
        "  elif re.search(\"^(insert into|include)\", sentence) or re.search(\"^([A-Za-z]+)+\\([\\W\\w\\d]*\\);?\", sentence) or re.search(\"^(add|Add|ADD)\", sentence) or re.search(\"^((C|c)lick on)\", sentence) or re.search(\"^((G|g)et)\", sentence) or \\\n",
        "        re.search(\"^(O?SCAR)\", sentence) or re.search(\"^((P|p)lease)\", sentence) or re.search(\"^((S|s)elect)\", sentence) or re.search(\"^((M|m)ove)\", sentence) or re.search(\"^((S|s)etup:)\", sentence) or\\\n",
        "        re.search(\"^((C|c)hange)\", sentence) or re.search(\"^((S|s)how)\", sentence) or re.search(\"^((U|u)pdate)\", sentence) or re.search(\"^((R|r)emove)\", sentence) or re.search(\"^((I|i)nclude)\", sentence) or\\\n",
        "        re.search(\"^[\\'\\\"\\`]?[A-Za-z\\s]+[\\'\\\"\\`]?\\=\\s*[\\'\\\"\\`]?\\_[\\w\\d]+[\\'\\\"\\`]?\", sentence) or re.search(\"^[\\w\\d\\s]+(\\-\\>)[\\w\\d\\s]+[\\.\\;\\?\\!]?$\", sentence) or re.search(\"^((F|f)ile (A|a)dd(ed)?:?)\", sentence) or\\\n",
        "        re.search(\"^[A-Za-z\\s]+\\=[A-Za-z\\s\\W]+$\", sentence) or re.search(\"^((B|b)uild (T|t)ag)\\s?\\:\", sentence):\n",
        "    return True\n",
        "\n",
        "  elif re.search(\"^\\d(st|nd|rd):?\", sentence):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_qwqeuz0nNlI"
      },
      "outputs": [],
      "source": [
        "def clean_data(sentence, s_type, old_sentence, list_start):\n",
        "  \n",
        "  #Rimuoviamo i caratteri � dalle stringhe e gli spazi all'inizio e alla fine\n",
        "  sentence = sentence.replace('�', '').replace(\"\", '').replace(\"\\‘\", \"\\\"\").replace(\"\\’\", \"\\\"\").replace(\"\\“\", \"\\\"\").replace(\"\\”\", \"\\\"\")\n",
        "  old_sentence = old_sentence.replace('�', '').replace(\"\", '').replace(\"\\‘\", \"\\\"\").replace(\"\\’\", \"\\\"\").replace(\"\\“\", \"\\\"\").replace(\"\\”\", \"\\\"\")\n",
        "  sentence = sentence.strip(\"\\\"\").strip(\"\\'\").strip(\"\\`\").strip()\n",
        "  old_sentence = old_sentence.strip(\"\\\"\").strip(\"\\'\").strip(\"\\`\").strip()\n",
        "\n",
        "  \n",
        "  \n",
        "  if re.search(\"^\\([\\w\\W]*\\)$\", sentence):\n",
        "    sentence = sentence.strip().strip(\"(\").strip(\")\")\n",
        "  elif re.search(\"^\\([\\w\\W]*\\)$\", old_sentence):\n",
        "    old_sentence = old_sentence.strip().strip(\"(\").strip(\")\")\n",
        "\n",
        "  flag_member, new_sentence = is_member(old_sentence)\n",
        "  #Se è un titolo\n",
        "  if (s_type == 'TITLE' or is_title(old_sentence)) and not flag_member:\n",
        "    #print(\"SKIPPO: \" + sentence)\n",
        "    return None, None\n",
        "\n",
        "\n",
        "  #Se è un inizio di una lista \n",
        "  elif s_type == 'LIST_START' and not re.search(\"^[\\W_]+$\", sentence):\n",
        "    list_start = sentence.strip(\"-\")\n",
        "    return None, list_start\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "  #Se è il membro di una lista\n",
        "  if (s_type == 'LIST_MEMBER' or flag_member) and not re.search(\"^[\\W_]+$\", sentence):\n",
        "    if list_start == None:\n",
        "      sentence = new_sentence.strip()\n",
        "    else: \n",
        "      sentence = list_start + ' ' + new_sentence\n",
        "\n",
        "\n",
        "\n",
        "  if sentence != None:\n",
        "    #Se la frase non rispetta certi requisiti non viene considerata\\\n",
        "    if is_skippable(sentence):\n",
        "      #print(\"SKIPPO: \" + sentence)\n",
        "      return None, list_start\n",
        "    else:   \n",
        "      sentence = re.sub('^[\\\"\\'\\`][\\\"\\'\\`][\\.\\;\\,]?$', '', sentence)\n",
        "      if(not is_quote_ok(sentence)):\n",
        "        sentence = sentence.replace(\"\\\"\", '').replace(\"\\'\", '').replace(\"\\`\", '')\n",
        "      sentence = re.sub('[\\;\\.\\,\\:]$', '', sentence)\n",
        "      sentence = re.sub('[\\s][\\s]+', ' ', sentence)\n",
        "      sentence = re.sub('(\\_|-){2,255}','', sentence)\n",
        "      if sentence[-1] != '?' and sentence[-1] != '!':\n",
        "        sentence = sentence + \".\"\n",
        "      sentence = sentence[0].upper() + sentence[1:]\n",
        "\n",
        "  \n",
        "  return sentence, list_start\n",
        " \n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_keywords_list(sentence):\n",
        "  listk = []\n",
        "  to_remove = []\n",
        "  for keyword in keywords:\n",
        "      if findWholeWord(keyword, sentence.lower()):\n",
        "            listk.append(keyword) \n",
        "\n",
        "  if not listk:\n",
        "    return listk\n",
        "    \n",
        "  for i in range(0, len(listk)-1):\n",
        "    for j in range(i+1, len(listk)):\n",
        "      if listk[i] in listk[j] and listk[i] not in to_remove:\n",
        "        to_remove.append(listk[i])\n",
        "      elif listk[j] in listk[i] and listk[j] not in to_remove:\n",
        "        to_remove.append(listk[j])\n",
        "\n",
        "  return [x for x in listk if x not in to_remove]"
      ],
      "metadata": {
        "id": "COoPXK9hoH9B"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "5tEOMPrwBjXX"
      },
      "outputs": [],
      "source": [
        "root = 'https://raw.githubusercontent.com/xDaryamo/NFR-Security-Extraction-Classification/master/'\n",
        "\n",
        "\n",
        "keywords = pd.read_excel(root + \"security_words.xlsx\").values.tolist()\n",
        "kws = []\n",
        "for keyword in keywords:\n",
        "  kws.append(keyword[0])\n",
        "keywords = kws"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIbtM1pWQ1FO"
      },
      "source": [
        "# Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkEZWELdDCKw",
        "outputId": "9a8fd6b6-c3b8-48fd-9a54-a1c607ed122d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-27 15:22:29--  https://github.com/xDaryamo/NFR-Security-Extraction-Classification/raw/master/riaz_dataset/riaz_dataset.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/xDaryamo/NFR-Security-Extraction-Classification/master/riaz_dataset/riaz_dataset.zip [following]\n",
            "--2022-11-27 15:22:29--  https://raw.githubusercontent.com/xDaryamo/NFR-Security-Extraction-Classification/master/riaz_dataset/riaz_dataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 520520 (508K) [application/zip]\n",
            "Saving to: ‘riaz.zip’\n",
            "\n",
            "riaz.zip            100%[===================>] 508.32K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-11-27 15:22:29 (13.4 MB/s) - ‘riaz.zip’ saved [520520/520520]\n",
            "\n",
            "Archive:  riaz.zip\n",
            "  inflating: riaz/CCHIT Certified 2011 Ambulatory EHR Criteria 20110517_PUBLISH.json  \n",
            "  inflating: riaz/EHR-Privacy-Security-Requirements_PUBLISH.json  \n",
            "  inflating: riaz/featureRequests - for annotation -PUBLISH.json  \n",
            "  inflating: riaz/HL7_Functional_Profile - PUBLISH.json  \n",
            "  inflating: riaz/nursing_ehr_business_and_functional_elements_june__2012_PUBLISH.json  \n",
            "  inflating: riaz/VLER UserStories Combined_PUBLISH.json  \n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/xDaryamo/NFR-Security-Extraction-Classification/raw/master/riaz_dataset/riaz_dataset.zip -O riaz.zip\n",
        "!mkdir riaz\n",
        "!unzip riaz.zip -d riaz/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "zUdg9nMA5-e3",
        "outputId": "e09d3a66-33a7-4e79-cc22-66ed0f5f6f2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing nursing_ehr_business_and_functional_elements_june__2012_PUBLISH.json ...\n",
            "Processing HL7_Functional_Profile - PUBLISH.json ...\n",
            "Processing EHR-Privacy-Security-Requirements_PUBLISH.json ...\n",
            "Processing featureRequests - for annotation -PUBLISH.json ...\n",
            "Processing VLER UserStories Combined_PUBLISH.json ...\n",
            "Processing CCHIT Certified 2011 Ambulatory EHR Criteria 20110517_PUBLISH.json ...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence  \\\n",
              "0  The vision of healthier Canadians through inno...   \n",
              "1  Once completed, the electronic health record (...   \n",
              "2  Canada Health Infoway's (Infoway's) Nursing Re...   \n",
              "3  Timely access to information will help inform ...   \n",
              "4  As part of the NRG, a pan-Canadian working gro...   \n",
              "\n",
              "                                            Entities  \\\n",
              "0  [The, vision, of, healthier, NORP, through, in...   \n",
              "1  [Once, completed, the, electronic, health, rec...   \n",
              "2  [ORG, ORG, ORG, ORG, ORG, 's, ORG, ORG, ORG, O...   \n",
              "3  [Timely, access, to, information, will, help, ...   \n",
              "4  [As, part, of, the, ORG, a, NORP, NORP, workin...   \n",
              "\n",
              "                                        Dependencies  \\\n",
              "0  [det, nsubjpass, prep, amod, pobj, prep, amod,...   \n",
              "1  [advmod, advcl, det, amod, compound, nsubj, ap...   \n",
              "2  [compound, compound, poss, case, poss, case, c...   \n",
              "3  [amod, nsubj, prep, pobj, aux, ROOT, xcomp, de...   \n",
              "4  [prep, pobj, prep, det, pobj, det, amod, amod,...   \n",
              "\n",
              "                                     Parts of Speech         File  \\\n",
              "0  [DET, NOUN, ADP, ADJ, PROPN, ADP, ADJ, NOUN, N...  nursing_ehr   \n",
              "1  [ADV, VERB, DET, ADJ, NOUN, NOUN, PROPN, AUX, ...  nursing_ehr   \n",
              "2  [PROPN, PROPN, PROPN, PART, PROPN, PART, PROPN...  nursing_ehr   \n",
              "3  [ADJ, NOUN, ADP, NOUN, AUX, VERB, VERB, DET, A...  nursing_ehr   \n",
              "4  [ADP, NOUN, ADP, DET, PROPN, DET, ADJ, ADJ, VE...  nursing_ehr   \n",
              "\n",
              "                                   Categories Security Words Security  \n",
              "0  [CONFIDENTIALITY, AVAILABILITY, INTEGRITY]       [access]        1  \n",
              "1                                        none           none        0  \n",
              "2                                        none           none        0  \n",
              "3                              [AVAILABILITY]       [access]        1  \n",
              "4                                        none           none        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23b255c7-abfb-4ee4-98e7-f12cac07287d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Entities</th>\n",
              "      <th>Dependencies</th>\n",
              "      <th>Parts of Speech</th>\n",
              "      <th>File</th>\n",
              "      <th>Categories</th>\n",
              "      <th>Security Words</th>\n",
              "      <th>Security</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The vision of healthier Canadians through inno...</td>\n",
              "      <td>[The, vision, of, healthier, NORP, through, in...</td>\n",
              "      <td>[det, nsubjpass, prep, amod, pobj, prep, amod,...</td>\n",
              "      <td>[DET, NOUN, ADP, ADJ, PROPN, ADP, ADJ, NOUN, N...</td>\n",
              "      <td>nursing_ehr</td>\n",
              "      <td>[CONFIDENTIALITY, AVAILABILITY, INTEGRITY]</td>\n",
              "      <td>[access]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Once completed, the electronic health record (...</td>\n",
              "      <td>[Once, completed, the, electronic, health, rec...</td>\n",
              "      <td>[advmod, advcl, det, amod, compound, nsubj, ap...</td>\n",
              "      <td>[ADV, VERB, DET, ADJ, NOUN, NOUN, PROPN, AUX, ...</td>\n",
              "      <td>nursing_ehr</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Canada Health Infoway's (Infoway's) Nursing Re...</td>\n",
              "      <td>[ORG, ORG, ORG, ORG, ORG, 's, ORG, ORG, ORG, O...</td>\n",
              "      <td>[compound, compound, poss, case, poss, case, c...</td>\n",
              "      <td>[PROPN, PROPN, PROPN, PART, PROPN, PART, PROPN...</td>\n",
              "      <td>nursing_ehr</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Timely access to information will help inform ...</td>\n",
              "      <td>[Timely, access, to, information, will, help, ...</td>\n",
              "      <td>[amod, nsubj, prep, pobj, aux, ROOT, xcomp, de...</td>\n",
              "      <td>[ADJ, NOUN, ADP, NOUN, AUX, VERB, VERB, DET, A...</td>\n",
              "      <td>nursing_ehr</td>\n",
              "      <td>[AVAILABILITY]</td>\n",
              "      <td>[access]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>As part of the NRG, a pan-Canadian working gro...</td>\n",
              "      <td>[As, part, of, the, ORG, a, NORP, NORP, workin...</td>\n",
              "      <td>[prep, pobj, prep, det, pobj, det, amod, amod,...</td>\n",
              "      <td>[ADP, NOUN, ADP, DET, PROPN, DET, ADJ, ADJ, VE...</td>\n",
              "      <td>nursing_ehr</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23b255c7-abfb-4ee4-98e7-f12cac07287d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23b255c7-abfb-4ee4-98e7-f12cac07287d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23b255c7-abfb-4ee4-98e7-f12cac07287d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "from pandas.io.common import dataclasses\n",
        "dataset_path = './riaz'\n",
        "df = pd.DataFrame(columns=[\"Sentence\", \"Entities\", \"Dependencies\", \"Parts of Speech\", \"File\", \"Categories\", \"Security Words\", \"Security\"])\n",
        "\n",
        "counter = 0\n",
        "list_start = None\n",
        "for file in os.listdir(dataset_path):\n",
        "    print(\"Processing \" + file + \" ...\")\n",
        "    with open(dataset_path+'/'+file) as f:\n",
        "      data = json.load(f)\n",
        "      \n",
        "    for i in range(0, len(data['content'])):\n",
        "      current_item = data['content'][i]\n",
        "      sentence = current_item['parserSentence']\n",
        "      full_sentence = current_item['sentence']\n",
        "      s_type = current_item['sentenceType']\n",
        "      ojective = current_item['securityObjectiveAnnotations']\n",
        "      sentence, list_start = clean_data(sentence, s_type, full_sentence,  list_start)\n",
        "\n",
        "\n",
        "      if not sentence:\n",
        "        continue\n",
        "\n",
        "      #print(sentence)\n",
        "\n",
        "      entities, dependencies, pos = features(sentence)\n",
        "      df.loc[counter, \"Sentence\"] = sentence\n",
        "      df.loc[counter,\"Entities\"] = entities\n",
        "      df.loc[counter,\"Dependencies\"] = dependencies\n",
        "      df.loc[counter,\"Parts of Speech\"] = pos\n",
        "      df.loc[counter,\"File\"] = current_item['documentID']\n",
        "\n",
        "\n",
        "      if not ojective or (len(ojective)) == 1 and (ojective[0][\"securityObjective\"] == 'DATABASE' or \\\n",
        "                                                    ojective[0][\"securityObjective\"] == 'TECHNICAL' or \\\n",
        "                                                    ojective[0][\"securityObjective\"] == 'MANAGEMENT'):\n",
        "\n",
        "        df.loc[counter,\"Security\"] = 0\n",
        "        df.loc[counter, \"Categories\"] = \"none\"\n",
        "\n",
        "      else:\n",
        "        df.loc[counter,\"Security\"] = 1\n",
        "        categories = []\n",
        "        for item in ojective:\n",
        "          if item[\"securityObjective\"] != 'DATABASE' and item[\"securityObjective\"] != 'TECHNICAL' and item[\"securityObjective\"] != 'MANAGEMENT':\n",
        "            if item[\"securityObjective\"] == 'AVAILABILITY_SURVIVABILITY':\n",
        "              if 'AVAILABILITY' not in categories:\n",
        "                categories.append('AVAILABILITY')\n",
        "            elif item[\"securityObjective\"] == 'INTEGRITY_IMMUNITY':\n",
        "              if 'INTEGRITY' not in categories:\n",
        "                categories.append('INTEGRITY')\n",
        "            else:\n",
        "              categories.append(item[\"securityObjective\"])\n",
        "\n",
        "        df.loc[counter, \"Categories\"] = categories\n",
        "\n",
        "      security_words = get_keywords_list(sentence.lower())\n",
        "      if not security_words:\n",
        "        df.loc[counter, \"Security Words\"] = 'none'\n",
        "      else:\n",
        "        df.loc[counter, \"Security Words\"] = security_words\n",
        "\n",
        "      counter+=1\n",
        "\n",
        "df = df.drop_duplicates(subset=['Sentence'])\n",
        "df.head()\n",
        "   \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJoYdZgH2esh"
      },
      "source": [
        "# Esportazione del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "qz8Cka5bTcOU"
      },
      "outputs": [],
      "source": [
        "df.to_excel('/content/drive/MyDrive/Security Extraction/dataset.xlsx',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UDfDpWsTV3N"
      },
      "source": [
        "# Esempio con una frase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Rsj2-1Kw1pd"
      },
      "outputs": [],
      "source": [
        "#df.loc[df['Security'] == 'TRUE'].iloc[0,0]\n",
        "nfr = \"The specifics of this issue is not addressed by any of the requirements, although Privacy Requirement 8, Privacy Requirement 9, Privacy Requirement 10, Privacy Requirement 11, and Privacy Requirement 12 specify that consent data be captured by POS systems and transmitted to the EHRi when transmitting the underlying PHI. Facebook\"\n",
        "doc = nlp(nfr)\n",
        "displacy.render(doc, style='ent', jupyter=True)\n",
        "displacy.render(doc, style='dep', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fqsvkYnuUMr"
      },
      "outputs": [],
      "source": [
        "data = [] \n",
        "for token in doc:\n",
        "    if str(token) not in punctuation:\n",
        "        data.append([token.text, token.pos_, token.dep_])\n",
        "\n",
        "print(tabulate(data, headers=[\"Text\", \"Part of speech\", \"Dependency\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "OfG8AfzUYk1u",
        "outputId": "1bb15235-af8a-4dd5-ddb1-b34cbd0ed420"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-b98dec1b83f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "df = df.drop_duplicates(subset=['Sentence'])\n",
        "df.head(25)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1TYQtpDJfiqNZL-ZBS8cUVKSAyw25ugak",
      "authorship_tag": "ABX9TyMpygktzraJu6cqWuxeqkjR",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}